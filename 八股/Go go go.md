Go go go

**-------你了解go的内存逃逸吗？**

内存逃逸是指本应该分配在栈上的变量，被编译器分析后发现生命周期超过了栈的管理能力，编译器就会把他放在堆上，比如变量过大无法放在栈上，就会触发内存逃逸，因为堆上的内存需要GC扫描挥手，所以逃逸过对会增加GC压力，影响性能。

通过什么来看逃逸分析？

go build -gcflags=-m

结构体实例逃逸到堆上会有怎么样的问题？

**-------说说go的内存管理**

go语言主要依赖自动垃圾回收和内存分配器来实现内存管理。对于自动垃圾回收，go主要使用的是并发，三色标记清除的gc算法结合写屏障和增量收集机制【这个需要在了解】，保证了低延迟和高吞吐；对于go的内存分配器，主要借鉴的是tcmalloc,把内存分成小对象/大对象，对于小对象，直接从本地的mcache分配，如果 mcache 不够，会向 mcentral/mheap 申请，速度快还没有锁的竞争；对于大对象没直接从全局堆中进行分配。奥，还有就是go的逃逸分析可以决定对象是在栈上还是在堆上，开发者就不必关心内存安全的问题，要是遇到内存逃逸，逃逸到堆上的内存才需要gc管理，留在栈上的会谁者函数端的返回自动释放

**Go 并发怎么实现？**

go的并发主要是通过goroutine实现的轻量级线程，每个goroutine占用很少的内存，通过go runtime内置调度器在少量操作系统线程上调度，也就是那个GMP机制【支持协作式调度和抢占式调度】；然后对于携程之间的通信和同步主要是通过channel来实现的，基于csp理论，不要通过共享内存来通信而是通过通信来共享内存，分为有缓存和无缓存，内部通过互斥锁来保证安全；然后在用select来实现对多个channel的监听来处理多路并发事件。

**-------go的Gc机制：**

##### 用的是并发的三色标记清除算法，主要分为标记和清除两个阶段，在标记阶段，他会把对向分为白色，灰色，黑色，对象最初都是白色，从根对象开始扫描，先变成灰色，等子对象都处理完后变成黑色，最后剩下的白色就是垃圾会被回收。标记阶段和用户程序是同时进行的，所以需要写屏障机制来保证安全，比如用户修改了指针，写屏障会把相关对象重新标记成灰色，避免勿回收。同时go的gc还会让携程协助gc完成标记，降低了stw的时间。go的Gc是追求低延迟，不追求高吞吐.

那么既然都有了写屏障了，为什么不能完全消除stw?

主要是写屏障它主要解决的时并发过程中对象状态变化导致标记不一致的问题，但是即使有写屏障，gc在某些操作下依旧会暂停用户程序也就是stw,比如说扫描根对象和清理阶段，在用户扫描根对象的时候并发进行修改栈或者全局指针可能会漏掉某些对象的引用被遗漏；而清除阶段回收白色对象需要确保此时没有携程正在访问这些对象，要是有可能会造成悬空指针的问题，加入stw就可以解决这些问题

**-------c++的map和go的有什么区别？**

C++的std::map底层是红黑树实现的有序关联容器，插入，删除，查找的时间复杂度是O(log n),遍历时可以保证顺序访问；如果是 `unordered_map`，它跟 Go 的 map 更接近，也是哈希表但是go的map底层是哈希表实现的，采用哈希通加拉链法来解决冲突，并通过增量扩容来提升性能，查找和插入的平均复杂度是O(1),但是kv是无序的，go的map默认并发不安全，需要配合锁使用。因为比较感兴趣，我看了一下gp实现map的源码，他的底层机构体时hmap,hmap结构表示一个哈希表，桶是bmap,里面存放的是tophash数组，overflow指针指向下一个桶，这个是以链表的形式将冲突哈希加入里面，Go 会把哈希值的低位用来决定落在哪个桶，高 8 位存在 `tophash`，用来加速桶内 key 的比较，所以查找和插入平均是 O(1)，但 key 是无序的。，在初始化map大小时，<8会调用makemap_small函数，>8的调用makemap函数，直接在堆上进行分配

**-------你能说一下go的channel吗？**

是go runtime实现的csp通信模型，底层是由hchan结构体实现的，这个结构体里面有四个重要的成员，环形缓冲队列，用来存放数据，sendx和revx指向环形缓冲队列发送的数据和接受的数据位置，以及sendq和revcq这两个等待发送队列和等待接收队列，和互斥锁。go的channel分为无缓冲channel和有缓冲channel,对于无缓冲channel,发送和接收必须同时发生。对于有缓冲channel,通过内部环形缓冲对列来解耦生产者和消费者，大概流程是这样，在环形缓冲区还有空位的时候，当发送者往环形缓冲区发送消息，首先会对环形缓冲区加锁，然后将要发送的数据copy到环形缓冲区，sendx++,然后在释放锁。只有在队列满或者空时才阻塞，在阻塞时为了提高性能，会和GMP搭配在一起使用，举个例子，对于发送方生产的太快或者接收方消费的太慢，那么环形缓冲对列满了，这时候runtime会检测到环形缓冲区满了，通知调度器，调度器会将发送者的状态改为waiting,此时会将发送者携程封装成一个sudog结构体，里面保存了channel相关的指针，从操作系统m中移除这个携程然后把sudog加入到sendq这个等待发送队列，然后从处理器的队列中取一个携程给操作系统线程并执行，这个时候就是之前发送消息的携程阻塞，但不是操作系统线程阻塞。当接收者从环形缓冲区接收一个数据时，会通知调度器，那么他会将发送者携程的状态由waiting变为runnable宁加入到处理器的队列里面。这是对于发送发阻塞的优化，对于接收者阻塞，那么他阻塞和前面差不多，但是当消费者向环形缓冲区发送数据的时候，也就是唤醒接收者时，他并不会去操作环形缓冲区，而是直接将发送者里面的数据copy到了接收者。

ai:

Go 的 channel 是 Go 语言在 runtime 层实现的 CSP 模型通信机制，本质上是一个 `hchan` 结构体管理的环形缓冲队列和等待队列。无缓冲 channel 必须发送和接收同时发生才能完成通信，有缓冲 channel 则可以先写入缓冲区，当缓冲区满或空时，发送或接收的 goroutine 会被封装成 `sudog` 放入等待队列，由调度器在用户态高效管理阻塞和唤醒，同时保证数据安全传递。也就是说，channel 在提供安全通信的同时，通过用户态调度避免了操作系统线程阻塞，实现了高性能的并发协作。

有没有想过用channel来解决go语言资源竞争问题而不是锁？

**Channel的缓冲区在用户态还是内核态**

用户态，通过runtime自己在用户空间管理。他的内存也就是hchan结构体里面的环形缓冲区，他时有runtime在用户态内存从堆开辟的一个普通的内存区域

**Goroutine阻塞等待的时候由谁来唤醒，需要额外的goroutine来遍历所有的channel么**

**-------csp的理念是什么？**

csp[communicating sequential processes]是通过通信共享内存，也就是各个携程之间不是通过直接通过传统的共享相同的物理地址老共享内存，而是通过channel来进行通信

**-------你能说一下go的context 吗？**

我觉得go的context主要是为了在携程间传递数据，信号和截至时间。比如context的Background()函数，一般用作顶层context;或者WithCancel(),可以返回一个cancel函数，用于手动取消；也可以时WithDeadLine()函数，基于父context创建一个带截至时间的context;也可以时WithTimeout(),基于父context创建带超时时间的context,底层也是调用的WithDeadlinr;也可以是WithValue,可以携带健对值

ai:

“Go 的 context 主要用于在 goroutine 间传递取消信号、截止时间和请求范围的上下文数据。
 常用 API 有：

- `Background()`：顶层 context；

- `WithCancel()`：返回可取消的 context 和 cancel 函数；

- `WithDeadline()` / `WithTimeout()`：创建带截止时间或超时的 context；

- `WithValue()`：携带请求级别的键值对（如 traceID）。
   使用时要沿调用链传递 context，不要存全局，操作完记得调用 cancel() 避免 goroutine 泄露。”
   
   ai:
   
   Go 的 `context` 主要用于 **在 goroutine 之间传递取消信号、超时控制、截止时间** 和 **请求范围内的数据**。
    它的设计初衷是为了让一条请求链路上的所有 goroutine 都能感知“请求结束”的信号，从而及时退出，避免资源泄露。
   
   ------
   
   ### 🌱 常用函数
   
   - **`context.Background()`**：最顶层、空的根 context，一般用于 main 函数、初始化或测试。
   - **`context.TODO()`**：和 Background 类似，但用于暂时还不确定要用什么 context 的场景。
   - **`context.WithCancel(parent)`**：基于父 context 创建一个可取消的子 context，返回 `(ctx, cancel)`，调用 `cancel()` 会通知所有下游 goroutine 退出。
   - **`context.WithDeadline(parent, t)`**：基于父 context 创建一个带“截止时间”的 context，到达指定时间自动取消。
   - **`context.WithTimeout(parent, d)`**：基于父 context 创建一个带“超时时间”的 context，本质上是对 `WithDeadline` 的封装。
   - **`context.WithValue(parent, key, value)`**：携带请求范围内的键值对，用于传递少量、非关键性元数据（例如 traceID、userID），但**不推荐滥用**来传递业务数据。

**-------你了解go的GMP吗**

G是go协程，M是抽象出来的线程，P是处理器，用来调度G和M的关系

GMP原理是指携程只有被处理器放入操作系统线程中才能运行，处理器会周期性的把携程调度到操作系统线程上运行，每个处理器都有自己的本地队列，当某个处理器对应的本地队列空了，他就会去访问全局队列，从中取出携程丢给操作系统线程运行，当全局队列也没有携程时，这个处理器就会去其他处理器的本地队列中偷一部分携程

**-------为什么要有p?**

其实之前是没有p的只有gm，那么会有问题，第一个问题就是由于没有处理器以及本地队列，那么每次操作系统线程要拿携程都要去全局队列里面，因为是全局队列，那么所有操所系统线程肯定是共享的，那么操作系统线程在全局队列拿携程的时候肯定时要加锁的，加锁取锁的操作会损耗性能，这是第一个问题；引入 处理器 后，每个 处理器 有自己的本地队列，操作系统线程 优先从本地队列取 携程 运行，提高 CPU 缓存局部性。还有一个就是当处理器本地队列是空的时候，他会尝试在全局队列或者其他的处理器的本地队列偷，保证负载均衡，减少操作系统线程的空闲时间。

**M上的G0是干嘛的**

他不是普通用户的携程，而时操作系统线程自己的携程，在造作系统执行调度或者系统调用时需要他来运行调度器代码

**GMP对CPU密集型任务能提高并发么**

**-------你觉得go和c语言有什么区别，在什么情况下用哪个？**

**-------golang中make和new有什么区别马？**【这个出过，但是事实上你答的并不好】

1：作用类型不同，new作用范围更广，可以给任何类型分配内存，make时给sclice,map,channel分配内存

2：返回类型不同：new返回的是指向变量的指针，make返回变量类型本身

3：内存操作不一样：new分配空间后会将内存请清0,make分配空间后会进行内存初始化

**-------说一下数组和切片的区别？**

数组在go语言里面其实用的比较少，长度一旦定义就固定，还有go的数组是值类型，不像c语言的数组他底层是指向数组的第一个元素的指针，所以在go中赋值或者传参还会整体拷贝，效率和灵活性都不高；而切片就用的多了，他是动态数组，本质上切片是一个三元组，指针指向底层数组，当前数组长度len,容量cap,他是引用语义，传参不会复制底层数组，而且还能按需扩容，在cap不够用时，他会通过append函数进行追加。

那么他可能问你，go的扩容机制是怎么实现的，你怎么回答？

调用append函数进行元素的追加

在现用数组长度+新增元素<=总容量，那么内部直接relice不会创建新数组；要是大于，那么说明底层数组不够用了，一般会创建一个是原来2倍大小的数组(Go 1.18 之后会根据增长策略动态调整)，然后把元数组的内容复制进去

那么他可能继续问你，要是slice底层数组特别大，但是只需要很小的一部分，这种情况可能会导致什么，怎样解决？

那你讲一下go 1.18之后他是怎样实现动态扩容的？

在1.17之前，cap<1024直接翻倍，不然就每次增加每次%25,在go 语言的 1.18之后，他不是以1024为界限，而是以256为界限的，这样避免了大切片突然翻倍导致的内存浪费，同时保证小切片扩容依然高效。

因为底层数组还被引用着，他会导致GC无法回收未用到的大部分内存。解决方法：通过copy到新的slice来释放原始大数组的引用，避免占用过多内存

 **Golang中的锁讲一下**

我对于go的锁有用过的有标准库sync提供的互斥锁和读写锁，互斥锁是sync.mutex,保证同一时间只有一个携程可以访问临界区；读写锁是sync.rwmutex,它允许多个读者并发，但是写的携程独占；

对于mutex的底层，主要分为快慢路径，首先携程会进行一次cas尝试获取锁，要是成功那么就进入临界区，着属于块路径，要是不成功，那么会进入慢路径，runtime会让携程在cpu上短暂自旋几次，在这期间要是锁被释放，那么他就会直接获取，避免了阻塞和唤醒的开销，要是自旋还没有成功，那么携程会挂到等待队列里面，并调用runtime的信号量挂起

对于mutex的调度模式他一共有两种，默认模式下，新来的goroutine可能会插队获取锁，这样的话可能导致其他的携程长时间得不到锁；还有一种模式是饥饿模式，就是当某个goroutine等待锁超过1ms,那么mutex会切换到饥饿模式，在饥饿模式下，锁的释放者会直接把所交给等待队列最前面，按照顺序来获取锁，保证了公平性

**注意：同一个携程重复加锁可能会导致死锁**

**他可能这样问，goroutine什么情况下会导致死锁**

go的锁他设计是不可重入性的，这样就可能导致死锁，通常是这样的情况，这个携程调用Lock(),此时锁状态会被标记成已锁定状态，然后再次调用Lock(),此时他会阻塞等待锁释放，但是他就会卡死到这里，因为前面根本就没有调用Unloc()释放锁

**那么项设计可重入锁，可以用channel来实现**

**可重入锁不是给多个协程同时获取**，而是允许“自己多次获取而不死锁”

ai:

1. **同一个 goroutine 可以多次获取锁**；
2. 锁内部维护一个 **计数器**；
3. 锁记录当前持有锁的 goroutine（或者线程 ID），只有计数器归 0 时才真正释放锁。

使用 channel 来实现：

- channel 用作二值信号量（容量为 1）控制访问。
- 使用一个 map 或 goroutine ID 记录当前锁被哪个 goroutine 持有。
- 维护一个计数器 `count`，记录重入次数。
- `Lock()` 时：
  - 如果是同一个 goroutine，计数器 +1；
  - 否则通过 channel 获取锁（阻塞）。
- `Unlock()` 时：
  - 计数器 -1，计数器为 0 时释放 channel，让其他 goroutine 获取。

**go语言map一个写+多个读会出问题吗？**

go语言的map时哈希实现的，要是一个携程在写时触发了扩容，那么此时会新创建一个hash，渐进式移动数据，要是此时另一个读携程正好在遍历或者访问某个桶，那么可能读到不完整数据，为了避免这种并发安全问题，Go runtime 直接禁止 map 的并发读写，一旦出现这种情况就会触发 `fatal error: concurrent map read and map write`。

那么就出现了下面这个

**sync.Map 的实现了解吗？/Sync.Map是如何保证并发安全的？**（回答一样）

我知道，这个主要是go标准库的并发安全map,我感觉就是map+sync.mutex的结合体，他的内部主要维护了两个map,一个是read map,只读，因为它主要负责处理读，因此可以无锁操作，效率比较高；dirty map,读写混合，写操作的时候会写入到dirty map。每当读取key的时候会先在read map里面找，要是没有就会触发慢路径读取，在dirty map里面找key进行读取，每次触发一次慢路径读操作时，就会把相应的计数器+1,当计数器达到一定阈值的时候，触发 **promotion**，就会将dirty map 里面的数据写入到read map里面，然后将dirty map清空，提高下一次的读效率；对于写：要是写入时这个key在read map里面存在，会把read map俩面的key标记成已删除状态。

**讲一讲sync.map 怎么取出值？**

调用Load(key)来取值，他会返回两个值：value,ok,ok标识key是否存在

select 如果都触发了，golang如何选择执行哪个case分支

interface的理解

go语言怎样实现单例模式

**-----defer 和 panic**

panic:go里的运行时异常，比如数组越界,nil指针解引用，或者手动调用panic(error),当panic发生的时候，runtimje会沿着调用栈向上逐层展开，执行每一层的defer,在defer种，要是调用了recover()并返回非nil,也就是panic被正常捕获，要是没有，

无语了，这个达的一坨

```
func main() {
    defer fmt.Println("1")
    defer fmt.Println("2")
    fmt.Println("3")
    panic("error")
}
```

3,2,1,error

首先这个程序会按照顺序开始执行，注册了两个defer

然后遇到了普通打印直接打印就好了

最后panic,程序触发了error,此时go会先执行所有已经注册的defer,因为defer是后进先出，因此第二个defer先执行，然后再执行第一个，因此是先打印2在打印1,defer执行完后，因为程序没有recover,那么他最终会抛出panic并打印panic:error

要是在defer中使用了recover,就可以步或这个panic,这样程序就可以恢复正常运行

要是加上recover应该是这样

```
 defer func() {
        if r := recover(); r != nil {
            fmt.Println("Recovered from:", r)
        }
    }()

    defer fmt.Println("1")
    defer fmt.Println("2")

    fmt.Println("3")
    panic("error")
```

在最前面注册一个defer，他是一个匿名函数，里面有recover(),...会先执行2,然后是1,最后是匿名函数，在匿名函数中会通过recover()获取panic,那么他会直接打印Recovered from: error，那么此时程序不会崩溃，而是会正常运行

**defer是怎么被处理**

在编译阶段，遇到defer会直接将defer生成两个运行时调用，将defer这一行变为runtime.deferproc,在函数最后一行加入runtime.deferreturn(),在运行阶段，运行到runtime.deferproc的时候，会创建一个 _defer结构体，把相应函数以及参数都记录在这个结构体中，并加入到携程的 _defer链表，然后在函数返回时会运行runtime.deferreturn,他会从携程的 _defer链表中取出延迟函数，并按照后进先出的顺序执行相应的函数

缺点：在程序里面频繁调用defer会产生一定的开销，因为每个defer会在堆上或者栈上创建一个_defer对象

注意这一点：

```
func inner() {
    defer fmt.Println("inner done")
}

func main() {
    go func() {
        inner()
        fmt.Println("goroutine done")
    }()
    time.Sleep(time.Second)
}
```

结果：

```
inner done
goroutine done
```

**要是问go的携程是怎样实现的**

携程时用户太轻量级线程，通过G-M-P模型在用户太调度，初始栈小，可动态扩展；通过channel来实现安全的携程间通信，比系统线程更高效

go的查bug?

Go 协程（goroutine）之间是 **怎样共享与通信的**？

携程上下文切换做了什么？



















