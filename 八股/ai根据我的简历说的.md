- Golang 和 C/C++:
  - 你提到熟悉 Golang 和 C，了解 C++。能详细说说你对这三种语言的理解吗？它们各自的优缺点是什么？
  - c语言偏低层，可以直接操作内存和指针，适合写操作系统，ebpf等这类内核级逻辑，缺点是程序员需要自己手动管理内存，出错成本比较高。c++语言我感觉可以堪称是c的扩展，增加了面向对象的特性，既保留了c语言的底层性能，有提供了更复杂的系统，但是就是语言复杂度变高，语法糖也很多，不容易深度学懂；go语言他有内置的携程和channel并发模型，配合GC机制让开发效率和可维护性都提高，比较适合云原声和分布式系统，但是他的错误处理相对繁琐
  - go语言中如何处理错误？
  - Go的错误处理主要是通过显示返回error值，调用方检查if err!=nil，这样保证了错误处理逻辑可见，可控，而不行异常那样隐藏控制流，对于不可恢复的严重错误，go提供了panic/recover,但只在极端情况下用
  - 在实际项目中，你是如何选择使用 Golang 还是 C/C++ 的？
  - 在 `wx_Os` 项目中，因为需要直接操作硬件和内存，并且对性能要求很高，所以选择了 C 语言。而在 `Wx_MQ` 项目中，因为需要高并发和分布式特性，并且希望提高开发效率，所以选择了 Golang
  - 你了解 Golang 的 Goroutine 机制吗？它与 C/C++ 的线程有什么区别？
  - goroutine是go提供的一种用户态的轻量级线程，由go runtime调度器管理，他的开销非常小，初始栈只有2kb,可以按需增长和缩小，因此同一台机器上能轻松跑成千上万个gorontinue,而c/c++的线程通常是映射到操作系统内核线程的，创建和切换都开销比较大，能创建的数量有限，通常 **受内存和操作系统调度器限制**，go运行时通过GMP调度器模型将成千上万个携程映射到少量内核线程，避免了频繁的系统调用开销，同时还能结合csp通信模型间哈并发编成，c/c++线程更偏性底层，性能高但是代码复杂，而go牺牲了灵活性，单大大提高了并发编成的效率
  - 
- Linux 开发环境:
  - 你熟悉 Linux 开发环境和常用命令，能说一些你常用的 Linux 命令以及它们的使用场景吗？
  - ls用于列出目录中的文件和子目录；cd进入某个目录；mkdir创建一个新的目录；rm删除文件；rm -rf产出目录；cat查看文件内容；chown修改文件或者目录权限；sudo用超级用户的权限执行命令；ps查看当前正在运行的进程，在电脑卡顿的时候我用他来查看占用资源最多的进程；kill杀死某个进程等
  - 你在 Linux 下进行过哪些开发工作？遇到过什么问题，又是如何解决的？
  - 我所写的项目以及开源的工作都是在linux环境下完成的...
- Git 和 Docker:
  - 你熟悉 Git 和 Docker 的基本使用，能说说 Git 的常用命令和 Docker 的基本概念吗？
  - 你在项目中使用 Git 进行版本控制的流程是怎样的？
  - 你使用 Docker 解决过什么实际问题？
- TCP/IP 网络协议:
  - 你熟悉 TCP/IP 网络协议，能说说 TCP 和 UDP 的区别吗？
  - 请解释一下 TCP 三次握手和四次挥手的过程。
  - 如果让你设计一个简单的 TCP 服务器，你会怎么做？
- 数据结构和算法:
  - 你熟悉常用的数据结构和算法，能说说你了解哪些数据结构？
  - 你了解哪些常用的排序算法？它们的时间复杂度和适用场景是什么？
  - 在实际项目中，你是如何选择合适的数据结构和算法的？
- 操作系统:
  - 你熟悉操作系统基本知识，能说说操作系统的作用是什么？
  - 你了解进程和线程的区别吗？
  - 你了解操作系统的内存管理机制吗？
- Linux 系统编程和网络编程:
  - 你熟悉 Linux 系统编程和网络编程，能说说你了解哪些系统调用？
  - 你了解 Linux 的 IO 模型吗？
  - 你使用过哪些网络编程相关的库？
- 分布式基础理论:
  - 你了解分布式基础理论，能说说 CAP 理论是什么吗？
  - 你了解一致性算法吗？
- MySQL 和 Redis:
  - 你了解 MySQL 和 Redis 的基本原理和使用，能说说它们的应用场景是什么？
  - 你了解 MySQL 的索引吗？
  - 你了解 Redis 的数据类型吗？
- eBPF:
  - 你了解 eBPF，能说说 eBPF 的作用是什么吗？
  - 你使用 eBPF 解决过什么实际问题？

**二、项目经历**

- eBPF 程序的 UT 补充:
  - 你在 Kmesh 社区的这个项目中主要负责哪些工作？
  - 你是如何基于 eBPF 单元测试框架实现对 sendMsg 和 cgroup 程序的高覆盖测试的？
  - 你如何保证测试的有效性和准确性？
  - 你在项目中遇到了什么技术难题，又是如何解决的？
  - 通过这个项目你学到了什么？
- wx_Os:
  - 你为什么选择开发一个 32 位的 UNIX 系统内核？
  - 你在 wx_Os 中实现了哪些功能？
  - 你在内存管理方面是如何使用 bitmap 实现高效的内存管理的？
  - 你在进程调度方面是如何实现基于时间片的抢占式轮询算法的？
  - 你在文件系统方面是如何借鉴 ext2 文件系统的设计思路的？
  - 你在开发过程中遇到了什么技术难题，又是如何解决的？
  - 这个项目给你带来了哪些提升？
- Wx_MQ:
  - 你在 Wx_MQ 中实现了哪些功能？
  - 你为什么选择使用 Golang 来实现这个项目？
  - 你如何使用 kitex 提供 RPC 支持？
  - 你如何使用 Zookeeper 存储元数据？
  - 你如何采用一致性哈希算法完成 Partiiton 和 broker 之间映射？
  - 你如何引入虚拟节点实现负载均衡？
  - 你如何基于 Raft 和 Fetch 机制来实现高可用性？
  - 你在开发过程中遇到了什么技术难题，又是如何解决的？
  - 这个项目给你带来了哪些提升？

## zhuMQ

 zhuMQ 是一个使用 Golang 编写的一个能够实时存储和分发数据、 支持多种格式的分布式消息队列。该项目采用 kitex 提供 RPC 支持， 使用 Zookeeper 存储元数据。对 Topic 进行分片，支持水平扩展集群。采取一致性哈希算法完成 Partition 和 broker 之间的映射，引入虚拟节点实现负载均衡，支持订阅发布模式和 pull 模式。基于 Raft 协议和 fetch 机制实现分布式高可用，zkserver 负责崩溃后业务转移和恢复后的副本复制（类似redis的哨兵集群？），可通过 ack 机制选择副本模式。通过顺序读写磁盘提高读写性能，采用稀疏索引标记位置加速消息查找。

- 强实时一致性用于交易结算、资金安全的场景很多，因为这些是敏感数据，用户很关注，如果不一致可能造成用户客诉，严重可能引发用户对平台的不信任；弱实时一致性允许一定的消息延时，多用于日志分析、消息推送等场景，即使有一定延时不会影响用户体验，生活中的例子就是小红书的消息推送。

### KafKa 和 Pulsar 的区别

- Topic：KafKa的Topic几乎都是持久化的，但是Pulsar分为持久化Topic和非持久化Topic,非持久化Topic不会持久化到硬盘中，当broker重启或者consumer发生故障时不会重新收到这条消息，优点是速度很快
- 消息去重方面：kafka保证至少消费一次，但是pulsar支持配置broker消息去重的选项，保证消息只会被持久化到磁盘一次。原理是为消息配置一个唯一的消息id,consumer中会维护相应的id队列，当broker返回ack之后，会将这个队列的相应id删除，开启消息去重后，收到一条消息就和这个队列id比较一下

### kafka和rocketmq的区别

最重要的区别有两点，一点是强顺序，一点是吞吐量

rocketmq是一个可靠消息，对消息顺序有要求的消息队列，但是kafka消息顺序保证是Partition级别

第二个是kafka吞吐量很高，支持**百万级日志流入HDFS/Flink，但是rocketmq在这一方面性能不如kafka**

- **Kafka** 偏向 **高吞吐、弱实时、日志流处理**，顺序保证是Partition级别。
- **RocketMQ** 偏向 **可靠消息、顺序/事务/延迟消息、企业级业务**，适合金融、电商核心业务。
- 如果你需要 **百万级日志流入HDFS/Flink** → Kafka。
- 如果你需要 **订单支付、交易消息、严格顺序或延迟消息** → RocketMQ。

### raft、ZAB、Paxos协议的区别

#### leader选举

- raft：悲观算法，raft中每个follower都有可能成为竞选者，主要看哪个follower的定时器先超时，会保证leader拥有最新最全的日志
- Zab：乐观算法，会直接选则日志同步最多的follwer成为leader（包含未提交的日志），leader和follower都能发起选举
- Paxos：两种选举方式都有，主要看不同的触发条件

#### 新leader是否提交前任leader未commit的消息

- raft：可能提交也可能不提交。leader上任会先同步日志，只有在当前任期下leader有新消息来后追加同步到各个节点日志，当有半数以上的节点返回ack,上一次未提交的消息会被顺带commit
- Zab：提交。先修改日志的epoch值和自己一样，然后广播。并且Zab要求先处理完前任消息才可以处理自己的消息

#### 脑裂问题

- raft + Zab：都存在脑裂问题
- Paxos：理论上允许多主，且多主情况下依旧正确，多主可以并发写入但是可能存在多锁问题，类似一个p2p网络（又称对等互联网络技术，是一种网络新技术，依赖网络中参与者的计算能力和带宽，而不是把依赖都聚集在较少的几台服务器上）

### 为什么用kitex而不是grpc

我之前在网上看到一篇博客，大概是说，kitex使用的协议主要都是基于 Thrift 以及一个高性能网络库netpoll，整体性能超过了grpc,并且提供了丰富的服务治理能力和支持多种协议，所以我当时就想着用kitex来作为我消息队列rpc框架

- **gRPC**：适用于跨语言的微服务系统，尤其在需要 HTTP/2 流式通信、高效的二进制数据序列化以及与其他使用 gRPC 的系统集成时，gRPC 是一个很好的选择。它在跨语言环境下的支持比较强，比如 Python、Java、C++ 等。
- **Kitex**：更侧重于 Golang 生态中的高性能 RPC 服务。对于 Golang 开发者来说，Kitex 提供了更强的定制能力和性能优化，尤其适合在字节跳动这样的高并发、高吞吐量环境下使用。Kitex 的灵活插件化机制可以让开发者根据需求选择不同的协议、序列化方式和负载均衡策略。

### ZKServer

- **元数据管理**：管理 Broker、Topic 和 Partition 的信息，并维护分区到 Broker 的映射关系。
- **Broker 连接与监控**：通过 ZooKeeper 管理 Broker 连接，动态扩展并监控其状态。类似kafka的协调者
- **负载均衡**：采用一致性哈希算法，在 Broker 和 Partition 之间进行负载均衡。
- **动态扩展**：支持动态增加 Broker，并在不影响现有服务的情况下重新分配工作负载。
- **高可用性**：通过 Raft 协议实现 Leader 选举、副本同步和容错。

### Raft

Raft呢是一个分布式一致性算法，他将一致性问题拆分成三个子问题，分别是leader选举、日志同步和安全性保证。正常情况下，会存在一个主节点为leader,剩下的是follwer,客户端和leader交互

他几乎所有的操作都采用两阶段提交，也就是leader收到客户端的请求后不会执行，而是写入到自己的日志列表中，然后将操作发送给follwer.follwer收到请求之后也只是写入到自己的日志列表，然后回复leader，当有超过半数的节点写入之后leader才提交这个操作返回给客户端，同时通知其他节点提交操作

#### leader选举

当定时器超时某个节点一段时间没收到leader的消息，认为leader已死，该节点变成竞选者，发起投票请求，并将这个请求term+1，这个请求中除了请求的term还包含竞选者最后一条日志的term和index，当收到超过半数的投票就成为leader并通知其他节点重置定时器。

- 如果出现了分区，分区也会选举leader,但是没办法收到绝大多数同意请求，所以无法选举成功。
- 新leader将任期加1
- 一个任期内只能给一个节点投票，保证一个任期只有一个leader
- 投票的规则：是否拥有更大的请求任期，日志任期相同是否拥有更新的index。
- 如果竞选者无法成为leader，则会等待超时重新选举
- 网络分区可能会产生多个，导致没有任何一个分区拥有大多数节点，无法成功提交日志，此时会陷入僵局，集群将变为 ”只可读“ 状态，直到网络恢复正常

#### 日志同步

Leader把请求作为日志条目（Log entries）加入到它的日志中，然后并行的向其他服务器发起 AppendEntries RPC复制日志条目。当这条日志被复制到大多数服务器上，Leader将这条日志应用到它的状态机并向客户端返回执行结果。某些follwer没有成功复制日志，leader会无限重试

#### 安全性保障

多数投票规则、提交规则保证了raft的安全性，也就是

- 已经commit的消息一定会存在于后续的leader节点上，不会被后续操作删除
- 没有commit的消息，可能会丢失

### redis 实现的mq 和你自己实现的 mq 有啥区别   你的有啥优点

![img](https://cdn.nlark.com/yuque/0/2024/png/47688958/1727183968400-16051074-97bc-424b-9bf8-d712e5df37cf.png?x-oss-process=image%2Fcrop%2Cx_15%2Cy_4%2Cw_883%2Ch_888)

**消息持久性：**redis消息不持久，kafka是持久的消息系统

**消息消费模式：**redis是广播消息给所有订阅者，但是kafka使用消费者组的形式

**性能：**redis基于内存，适用于低延迟高吞吐量；kafka采用分布式，适用于大规模数据流

**redis适用于实时低延迟，kafka适用于高吞吐量、持久化和分布式场景**

### zhuMQ有做重复消费吗

zhuMQ 保证至少一次消息投递（通过ack机制），所以会出现消息重复的问题，消息队列本身不保证消息不被重复消费（这是业务层保证的），但是可以保证消息的幂等性

- 可在内存中维护一个set，只要从消息队列里面获取到一个消息，先查询这个消息在不在set里面，如果在表示已消费过，直接丢弃；如果不在，则在消费后将其加入set当中。
- 让生产者发送消息时，每条消息加一个全局的唯一id，然后消费时，将该id保存到redis里面。消费时先去redis里面查一下有么有，没有再消费。

### 常见消息队列区别

|                                                              | Rabbit mq                              | Rocket mq                                                    | Kafka          |
| ------------------------------------------------------------ | -------------------------------------- | ------------------------------------------------------------ | -------------- |
| 优点                                                         | 支持多种消息队列协议                   | 单机吞吐量：十万级                                           | 高可用，性能好 |
| 在Producer和Queue之间增加路由模块，路由配置很灵活（根据配置的路由规则将生产者发出的消息分发到不同的队 列中） | 支持10亿级别的消息堆积                 | 消费者采用Pull方式获取消息, 消息有序, 通过控制能够保证所有消息被消费且仅被消费一次 |                |
| 健壮、稳定、易用、跨平台、支持多种语言                       | 可靠性高，高并发，功能支持完善         | 有优秀的第三方管理界面                                       |                |
| 缺点                                                         | 对消息堆积处理得不好                   | 支持的客户端语言较少                                         | 延迟高         |
| 性能有瓶颈                                                   | 与周边生态兼容不是很好，社区活跃度一般 |                                                              |                |
| 开发语言学习难度大                                           |                                        |                                                              |                |

### 心跳

分为两种，**raft机制下的心跳**和**zkserver发布的心跳**

raft机制的心跳是用来判断leader是否存活，zkserver心跳判断消费者是否存活

由zkserver来管理，他相当于群组的协调者

- 不断发送PingPong请求检查**消费者**是否活跃，是否存活
- 不管生产者的死活

### 单点故障怎么办

- 消费者：zkserver通过心跳检测单点故障，当一个节点下线，zkserver会移除这个节点
- broker：raft 机制保证了单点故障后重新进行leader选举

### 消息积压怎么解决

分两点回答：预防消息积压和解决消息积压

- 解决消息积压是通过水平扩容增加consumer数量
- 对生产者进行限速
- 增加partition数量
- **优化消费者处理速度**：提升消费者的消费速度也可以避免消息积压的问题，它的解决方案有：优化消费者处理消息的逻辑，减少不必要的计算和 I/O 操作。

- 优化消费者处理消息的逻辑，减少不必要的计算和 I/O 操作

- 对于可以并行处理的任务，使用多线程或异步处理来提高吞吐量。

### 消息顺序相关问题（消费、存储磁盘）

**消息消费顺序问题**

- **分区有序性**：每个 Topic 的消息不能保证有序，但是每个 Partition 的消息可以保证有序。如果想让消息有序，可以将消息发送到同一个 Partition
- **消息offset**：每个 Partition 是采用追加写的方式，每条消息有独一无二的offset
- **消费者组与有序性**：

- Kafka 允许多个消费者组成一个消费者组来并行消费消息。在同一个消费者组内，Kafka 确保同一个分区中的消息只会被同一个消费者消费，从而保持该分区内的消息顺序。
- 不同消费者组之间的消费顺序是没有保证的，这意味着同一条消息可以被多个消费者组并行消费，但在每个消费者组内部是有序的。

- **消息发送与确认机制**：有ack确认机制，保证生产者生产消息时

**消息存储顺序问题**

- 往磁盘里顺序写入
- 文件结构：

- Kafka 将每个分区的数据存储为一系列的段文件（segment files），每个段文件中保存一组顺序写入的消息。
- 当段文件达到一定大小后，Kafka 会关闭当前段文件并开始新的段文件。这种分段结构使得在读取时可以高效地定位消息。

### 消费者偏移量offset

zhuMQ的offset是手动提交，每个消费者手动维护在Partition中的消息位置，所以可能发生重复消费的问题

### 生产者和消费者的流程

##### producer push message

当有生产者生产信息时，（有做缓存）生产者会先连接zookeeper,查询该信息将交给谁来接收（负载均衡算法）；当有生产者生产信息时，向 zkserver 查询该向谁（broker）发送（一致性哈希算法），zkserver 将发送信息到该 broker,broker检查 topic 和 partition 是否存在，不存在就创建并且启动该 partition 接收该功能（设置该 partition的接收队列和文件）

##### consumer sub and startToGet

当有消费者消费信息时，向 zkserver 查询该向谁（broker）发送请求，zkserver 判断是否订阅了该 topic/partition ，若没有则返回，若有，zkserver 向 broker 发送信息，若该 broker 没有该订阅则创建一个，并根据 file_name 创建 config，并负载均衡，发送信息；

当消费者消费信息时：连接到 Zookeeper（Broker），查询该节点是由那个 Broker 负责，重新连接该 Broker，进行消费；

- 对于 PTP 的情况，消费者将获得对该 Topic 的消费信息，和对各个节点的消费情况，连接到 Brokers 后将它们负责的 Partitions 的情况发送过去，并开始消费。
- 对于 PSB 的情况，消费者获取该 Topic——Partition 所在 Broker 节点后，将自己给出想要消费的位置进行消费。

当 zkserver 上的负载均衡发生改变时，需要将停止一些 broker 上的接受 producer 的信息的服务，转移到其他地方去。zkserver 需要发送到该 broker，停止信息，并将文件名进行修改，若有 consumer 在消费这个文件，则修改 config 中的文件名等，发送到新 broker 去接收信息。

当 borker 中一个 file 消费完后，将发送结束信息到 consumer，consumer 将再次请求 zkserver 去获取下一个 broker 的位置。

### zhuMQ的稀疏索引

zhuMQ的消息存储仿照了kafka,做了一个类似的稀疏索引。他有 Topic 和 Partition 两个概念，一个 Topic 可以有多个 Partition。在实际存储的时候，Topic + Partition 对应一个文件夹，这个文件夹对应的是这个 Partition 的数据。在文件夹下，消息采用 Segment 段 的形式进行存储，段 下面又细分成index（索引文件）和 log（数据文件）。索引文件命名是数字格式，名称表示消息的偏移量。

![img](https://cdn.nlark.com/yuque/0/2025/png/47688958/1741769787421-775a819e-ec4c-45fd-b4fb-8b9cbcdb53bb.png)

比如说第一条消息偏移量是368770.

索引文件简单的存储数据，格式是[N, Position]，n表示索引文件第几条消息，Position表示该条消息在数据文件里的物理偏移。

![img](https://cdn.nlark.com/yuque/0/2025/png/47688958/1741770261160-1ff7b514-b14e-4274-a0c6-b65a04dd8ce0.png)

### 消息巨大导致稀疏索引原本放置300条消息的log只能放下一条消息了

消息压缩（相应的压缩算法，比如gzip等，这些算法的原理是通过寻找重复数据和无用数据来减少数据大小），但是zhuMQ没做这个功能。

### 