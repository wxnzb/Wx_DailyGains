操作系统

**%%%%%执行一个可执行文件的流程？**

首先，操作系统会将程序加载到内存，解析可执行文件的元数据，并将程序的各个段映射到进程的虚拟空间中，然后，操作系统为该程序创建一个进程，并分配必要的资源，然后，，程序的堆栈会被初始化，程序计数器和栈指针会被涉及到程序的入口，然后操作系统切换到用户态开始执行程序。

**%%%%%写入文件执行的整个流程**

首先应用程序通过系统调用请求向文件写入数据，操作系统会找文件描述符，定位文件对向和存储位置，确保文件以打开并有写入权限。然后，为了提高性能，数据会先写入文件缓存区，在根据缓存策略决定何时将文件混充去内容刷新到磁盘，写入文件完成后，操作系统会更新文件元数据，比如文件大小和修改时间等

**%%%%%cat xxx.txt 的运行过程**

shell会解析命令并调用操作系统的exec系统调用来启动cat程序。操作系统将cat的可执行文件加载到内存，接着，cat程序通过open系统调用打开.txt文件，并获得文件的文件描述符。程序通过调用read系统调用读取文件内容，操作系统将文件从磁盘加载到内核缓存区，cat程序逐行读取文件内容并打印到终端。读取完后，cat关闭文件并推出，shell返回命令提示符，整个流程完成。

**%%%%%怎么在磁盘上找到一个文件**

要想在磁盘上找到一个文件，主要依赖文件系统的目录结构和索引机制。首先操作系统会先根据路径从根路径向下查找目录项，目录向里面包含了文件名和inode编号，inode记录了文件的元信息，包含文件大小，权限，存储在磁盘上的数据块的地址，通过 inode 里的数据块指针，就能定位到磁盘上的物理存储位置，从而读取或写入文件内容。

**%%%%%将文件A插入文件B操作**

这个本质上，是将文件a的内容读出来，并在文件b的某个地方写入。先通过系统调用open打开ab文件，内核会找到文件b的inode信息。操作系统先把文件a的数据读入到内存缓冲区，然后在文件b中指定写入偏移，把数据从内存写入到文件b的缓存区，写入过程中如果需要扩展或移动数据块，文件系统会负责重新分配，并更新 B 的 inode 中的数据块指针和文件大小，最后把缓存刷新到磁盘，完成插入操作

**%%%%%文件页缓存(page  cache)如何写回磁盘**

又同步和异步两种策略，同步写时，系统调用会阻塞直到数据写入到磁盘；异步写时，数据先在缓存中保留，之后又内核后台线程扫描脏页并写回磁盘，并更新inode元数据

扩展:脏页值的是已经被修改但同步到磁盘的内存页

**%%%%%open文件时发生了什么？**

程序调用open打开文件时，用户态会发起系统调用进入内核，内核首先会根据路径名从根目录找到目录项，从而找到对应的inode,并检查当前进程是否有相应的访问权限。接着，内核会为这个文件创建一个file结构体，保存文件的打开状态（如读写偏移、模式），并让结构体内部成员指针指向该 inode，，并把这个File结构体放在内核全局文件表中，内核在当前进程的文件描述符表中分配一个最小可用整数，执行file结构体，并把这个整数返回给用户态，之后应用程序就可以通过文件描述符来对文件进行读写操作

内存缓冲区-page cache

**%%%%%你了解虚拟内存吗？**

虚拟内存是操作系统体构的一种内存管理机制，他是在进程看到的地址和真实的物理地址间加了一个抽象，每个进程都认为自己有一块连续的大内存，实际上进程里看到的这些虚拟地址会通过页表映射到物理内存或者磁盘上

那么肯定会准问，那这样有什么好处，为什么要这样设置？

实现了进程之间内存隔离；解决了物理内存不足的问题，因为它可以通过页表把部分虚拟内存映射到磁盘；提高了内存利用率，不同的虚拟内存可以映射到相同的物理内存中的只读数据

**%%%%%要是没有虚拟内存会怎样？**

要是没有虚拟内存，进程只能直接用物理内存，会带来几个问题，首先，进程间无法实现隔离，一个进程的数据可能被另一个进程篡改；内存利用率低，物理内存必须按块分配，容易产生严重的碎片问题；安全性也比较差，一个程序的错误可能直接导致整个系统崩溃。

**%%%%%怎样避免物理内存碎片化？**

内存碎片化可以通过引入虚拟内存和分页机制来避免，把进程看到的虚拟地址空间分成固定大小页，映射到物理内存的页框，这样就避免了分配连续大块内存，解决了外部碎片，对于内部碎片化，操作系统可以结合伙伴系统和slab分配器解决

扩展：

外部碎片：是总空闲内存足够大，但是分布不连续，无法满足大块申请；比如说现在我申请了100kb,150kb,100kb,然后释放了两个100kb,现在我要申请200kb，但是因为不连续，因此还得重新申请

内部碎片：是分配器在返回内存时，分配给程序的块比实际请求的要大；比如现在有个分配器内部有最小分配力度64kb,现在你申请了100kb,那么分配器会给你分配两个64kb的块=128kb,那么就会有28kb的内部碎片产生

怎样避免内部碎片：

**%%%%%那你了解伙伴系统马？**

伙伴系统是一种高效的内存分配和回收算法，他主要为了解决内存碎片化问题。他将内存划分为2的米次方大小的块，每个块都有一个伙伴。当分配内存时，系统根据请求大小向上取整到最近的2的米次方，要是当前没有空闲块，就会再上一级将他进行拆分，拆分出来的子块互为伙伴。在释放内存时，要是释放块的伙伴，那么可以进行向上一致合并，从而减少了内存碎片化

**%%%%%了解malloc的底层实现吗**？

当申请小内存时，malloc使用sbrk分配内存，他主要是将堆顶的sbrk指针向上移动来扩展堆的大小；当申请大内存时，使用的时mmap函数，这里无论时sbrk还是mmap他们申请的都是虚拟内存，为了提高性能，在访问申请的虚拟内存时再会根据缺页中断在内核中调用伙伴系统给他分配相对应的物理页，并建立虚拟内存和物理内存的映射。由于sbrk和mmap都是系统调用，那么每次申请内存，都要产生系统调用开销，这样会带来了两个坏处，第一就是上下文切换十分影响性能，其次就是这样申请容易产生碎片【因为堆是从低地址像高地址，要是低地址的内存没有释放那么高地址的内存也释放不了】那么为了解决这个问题，malloc采用了内存池的实现方法，首先申请一块大内存，然后将内存分为大小不同的内存块，malloc将大小差不多相同的内存块通过双向链表连接起来形成一个bin,malloc一共管理128个bin，像fast bin,small bin,large bin等等,每个bin都有自己适用的条件【像fast bin,就是程序运行连续申请小块内存，这样可能小的内存空间用完会在大的内存空间切出一块，这很费时间，那么fast bin就很好的解决了这个问题，在不大于max_fast的内存块被释放时，他不会被立即释放，他会将这个内存块存到fast bin里面。对于对于分配大内存，这里还有个特殊的sorted bin,他主要是在要是在fast bin只没有找到合适的内存块，那么会将fast bin内存块进行合加入到sorted bin中，就会在sorted bin中找，要是他也不能满足分配，那么会将sorted bin里面的内存块加入到后面的 large bin里面，那么现在往后遍历数组的bin还是没有分配到内存，那么首先他会在top chunk中为他分配内存，这里的top chunk是从mmap区域分配的一块大的空闲内存，要是这个也不满足，那么会直接从mmap来直接使用内存映射。】上面采用内存池的方法起始就是arena内部维护的，但是在面对多线程操作malloc，为了避免数据竞争，会添加互斥锁，但是发现这种情况每次只能处理一个线程效率太低了，那么就为每个线程分别创建一个arena,创建新的arena时候，arena会向此操作系统生成一块大的虚拟内存，这样就避免了同时去抢同一片空间的问题，但是这里又有一个问题，内存会被划分为free,used和available，free是不占用物理内存的，used和available都是占用物理内存的，但是used是应用使用的内存，但是available是没有被应用程序使用但是还占有物理内存的，这里需要均衡arena的数量，要是太少，会产生竞争问题，要是太多，有会产生内存碎片化问题，因为要是线程a的arena里面的available他有一块内存，比如说20kb,现在线程b需要申请20kb，但是由于线程a和线程b有不同的arena,所以用不了线程a的available,这就需要均衡处理。

**%%%%%了解tcmalloc吗?**

但是对于tcmalloc,他主要分为三个组件，front-end和middle-end和back-end,每个线程都有属于自己的front-end,共用middle-end,对于malloc遇到的问题不会存在，首先要是线程a有20kb的available,那么他会将他放入middle-end中，要是线程b要申请20kb内存，他会先在middle中找，ok，找到了直接用就行了，可以解决malloc的问题

**%%%%%进程，线程，携程的区别？**

进程是资源分配的最小单位，线程是cpu调度的最小单位。进程拥有独立的内存空间，进程间资源相互隔离，进程里的进程贡献内存，但也拥有独立的寄存器，栈，上下文切换开销比进程小；携程他是用户态轻量级线程，依附于线程，是一对多的关系，切换开销极低，适合高并发

**那你知道携程有哪几种吗？**

携程分为有携程和无栈携程，goroutinue是有栈携程，拥有自己的上下文和执行栈，支持动态伸缩栈，无栈携程是一个线程共享携程栈，内存占用低，切换成本低，效率高，但是需要编译器状态机支持

**%%%%%进程间通信方式你知道哪些？**

首先每个进程他们从虚拟地址对应的物理地址中，用户地址空间是独立的，但是他们共用内核物理内存，因此要实现进程间通信，那么可定时要通过内核的，那么就有一下几种方式：

管道，消息对列，共享内存，信号量和信号，socket

管道：首先管道的类型分为匿名管道和命名管道，他们就是内核里的一串缓存，缓存的数据是无格式的流大小受限。那么想实现进程间通信，简单的是通过fork来实现父子进程间的通信，现在父进程通过pipe函数创建匿名管道，创将两个读写管道，然后fork一个子进程，因为创建的子进程会复制父进程的文件描述符，那么现在两个进程都有两个读写管道，为了避免混乱，一般就留下一个读的或者写的实现跨进程沟通。然后想要实现没有什么关系的进程间通信，他主要是创建命名管道，这个命名管道就是两个进程间进行交互的桥梁

消息队列：因为管道通信方式比较低效，不适合进程间频繁进行交换数据，那么就引入了消息队列。消息队列是保存在内核中的链表，他将要传递的消息体放在链表中即返回，然后接收者再从链表中读取，但是他对于消息体的大小有限制然后就是有数据在用户态和内核态之间的拷贝开销

共享内存：共享内存可以完美的解决用户态和内核态之间消息拷贝的开销问题，因为他等于是让生产者和消费者共享一块内存来实现消息的传递的，每个进程的虚拟空间对应的用户态物理内存是不一样的，那么就让他对应一样的物理内存就实现了内存共享(那我感觉这个跟上面说的内核没什么关系啊：共享内存虽然需要内核来建立映射，但真正读写数据是在用户态直接完成的，所以避免了频繁的内核态拷贝)

信号量：因为在共享内存的时候，要是有多个进程共享内存，那就可能会产生竞争，为了保证在任意时刻共享内存里的资源只能被一个进程访问，就出现了信号量。信号量起始是一个整形的寄存器，主要用于实现进程间的同步和互斥。对于互斥来说，需要将信号量初始化为1,当有一个进程访问资源时，就将这个信号量进行p操作也就是-1,这时候信号量变成0了，要是还有进程想要访问，发现再减就<0,就等待，此时要是上一个进程访问完释放了资源就是时的信号量+1然后唤醒阻塞的进程。同步是为了进程间能按照一定的顺序合作完成，那么需要将信号量初始化成0，这样假设现在有两个线程a,b,a负责生产消息，b负责读取消息，要是现在b先执行了，在p时信号量会变成-1,表示a现在还灭有生产数据，此时a阻塞，知道a生产了数据，信号量变成了0,就会唤醒b

信号：信号时为了通知进程有异常事件发生

socket:上面讲的都是在一台主机上的进程通信，要是想要实现不同之间的主机进行通信，那么就需要网络，就要用到socket，但是socket不仅可以跨即，也可以在本地，但是他不像tcp和udp那样，需要绑定ip地址和端居欧，而是绑定一个本地文件就可以了

**%%%%%死锁是怎样形成的**？

他需要满足四个条件才可以，互斥条件，持有并等待条件，不可剥夺条件，环路等待条件。

首先对于互斥条件就是一个共享资源在任何时可只能被一个进程持有；持有并等待条件是指一个进程持有1个资源但是他还像在持有另一个资源，但是另一个资源已经被另一个进城持有了，那么现在他就时等待状态。不可剥夺条件是指，一个资源只有被持有的进程时用完并释放之后才能被其他进程拥有（我怎么感觉这个和互斥说的这么像呢，还是不一样的，这个主要强调的时不能强行夺取);环路等待条件，就是a池有了资源1等待资源2,b持有资源2等待资源1这样就形成了环路等待

**%%%%%怎样排查死锁**？

可以通过pstack(它可以显示每个线程的栈跟踪信息)和gdb来进行排查。

通过pstack 进称号，多次进行调是，发现结果都一样，可以看到两个线程一直阻塞在获取锁的状态，当时就可以知道那可能是出现四所状态了，然后用gdb来进行调式，我通过info thread来打印线程信息，切换到阻塞的线程，通过调用栈发现他在等a的锁，然后查看a的锁在哪，发现在量一个线程持有，而另一个线程又在等待这个线程已经持有的线程a

**%%%%%怎样解决死锁**

要打破索引，只需要破坏那四个条件中的一个就行了，可以使用资源有序分配法来破坏环路等待的条件，就是a线程和b线程要获取a,b锁，那么他们获取锁的顺序必须要保持一致，这样就可以了

**%%%%%讲一下大端和小端？**

地址就跟我们好图一样，喜欢从左到右是从小到达，那么地址也一样，从做到有就是低地址到高地址。

大端是将字节从高位到低位就像我们平时写数字一样；小端则是将字节从低位到高位。网络协议统一使用大端，x86架构是基于小端的

**%%%%%docker的底层原理：**

docker本质上不是虚拟机，它主要是利用linux内核提供的隔离和资源控制能力时显得轻量级容器话技术。它主要包括：namespace:进程隔离，docker里的每个容器就是一个进程，运行在namespace里面，他里面将进称号，网络什么的都进行了隔离；cgroups:资源限制：用来限制容器能使用的资源，防止了某个容器无限制的占用宿主机资源，保证多容器的公平性；overlayfs:分层文件系统：分成镜像层和容器层，镜像层是共享只读，容器是是分离可写

**%%%%%抢占式调度和非抢占式调低的区别：**

抢占式调度允许正在运行的进程被中断，从而把cpu分配给更高优先级的任务；

非抢占式调度时进程需要触动染出cpu才会被切换

**%%%%%冯诺伊曼体系结构：**

很久以前数据和程序存储地方是不一样的，数据存储在存储器，程序则存储在控制器，他提出了，将程序编码为数据和数据一起存放在存储器，实现了硬件和软件的分离
核心思想：
程序，数据以二进制都是先存在主存储器中，确定了计算机的五个组成部分：运算器，控制器，存储器，输入设备，输出设备
运算器的主要部件是算术逻辑单元alu,在控制信号的作用嗯下，完成算术运算了逻辑运算
控制器是计算机控制中心，他的流程：从内存取指令，翻译指令，分析指令，控制相关操作
存储器

**%%%%%时间轮？具体说下底层**

时间轮是一种高效管理大量任务的调度算法，通过环形数组来管理定时器。环形数组里面有slot数量【slot=槽位】，每个slot都是一个连链表，链表里面存放该时间点需要触发的任务；tick大小代表每次移动一个槽位经过的时间，每次tick移动，就会检查槽位，轮数=0 的执行，轮数>0 的减一。当前指针就是指向当前的槽位；假设现在有8个槽位，tick=2,当前指针=1,任务a是延迟21秒，那么他会放在哪里呢？

那就需要计算槽位和轮数：

槽位：（1+【21/2】向上取整）%8=4

轮数：21/2/8=1

优点：他只需要维护一个固定大小的数组，节省了内存；他插入是 O(1)，删除平均是 O(1)，最坏情况下可能退化成 O(k)，复杂度较低

缺点：不适合做长时间任务，只适合做短期，因为长任务他的时间轮可能很大，无法表示；然后就是他的灵活性不高，要是大多数任务都被分到同一个曹位，就会退化成链表；还有就是将任务容易，删除任务还需要扫描链表，比较麻烦

可以将他结合小根堆使用

小根堆：完全二叉树，每个结点小于等于子结点，也就是对的到小从上往下看是从小变大，他在插入时，会从堆低往上遍历，插入时O(logn),他删除是往下遍历，时间复杂度O(logn),获取最小值往下遍历，O(1),他嫩感召时间顺序处理所有任务，适合长时间任务

那么量者结合在一起，就可以解决长任务和短任务的问题

**%%%%%能讲一下select,poll和epoll的关系吗？**

select实现多路复用的方式是将以连接的socket都放到一个文件描述符集合，然后调用select函数将文件描述符集合拷贝到内核里，让内核来检查是否由网络事件发生，检查方式，通过遍历文件描述符的方式，当检测到有事件产生时，将次socket标记为可读或者可写，接着再把整个描述符集合拷贝回用户态里，然后又用户态还需要在遍历找到可读或者可写的socket,然后对他进行处理。而poll和select的区别就是解决了select1024限制问题，性能上没有什么优化。那么epoll是怎样做的，epoll在内核中使用红黑数来跟踪所有待检测的文件描述符，红黑数是个高效的数据结构，曾删改一般事件复杂度为logn;epoll具体实现原理，epoll使用事件驱动机制，内核维护了一个链表来记录就绪事件，当某个socket有事件发生时，通过回调函数内核将这个socket加入到就绪事件中，当用户调用epoll_wait函数时，会返回就绪事件列表中的个数，不需要像select/poll那样轮询扫描整个socket集合，达到提高了检测效率

**%%%%%什么是中断**

中断是系统用来响应硬件请求的一种机制，操作系统在收到硬件中断请求时，会打断正在执行的程序，调用内核中断来响应请求

通俗来讲，就像你在公司完成一项任务，这是紧急开了一个会，这个会就像中断，我们快速去开完，更有利于我们完成下面的工作

**%%%%%硬中断vs软中断**

情况：要是中断处理时间过长，其他设备发来中断请求可能会丢失

就像你还是被拉去开会，在开会过程中，又有了一场会议需要你参加，但是你参加不了了

解决方法：将中断过程分为上半部分【硬中断】和下半部分【软中断】

上半部分用来快速处理中断，下半部分用来延迟上半部分未完成的工作

就那上面的举例，我依然被拉去开会，在会上我让将重点，后面的之后让同事讲给我，那么我就可以继续参加第二场会议了

应中断是处理硬件请求，回答端cpu正在执行的任务，需要快速执行

软中断是内核触发，耗时较长

**%%%%%了解linux用了哪些命令**

