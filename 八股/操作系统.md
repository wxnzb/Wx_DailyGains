操作系统

**%%%%%执行一个可执行文件的流程？**

首先，操作系统会将程序加载到内存，解析可执行文件的元数据，并将程序的各个段映射到进程的虚拟空间中，然后，操作系统为该程序创建一个进程，并分配必要的资源，然后，，程序的堆栈会被初始化，程序计数器和栈指针会被涉及到程序的入口，然后操作系统切换到用户态开始执行程序。

**%%%%%写入文件执行的整个流程**

首先应用程序通过系统调用请求向文件写入数据，操作系统会找文件描述符，定位文件对向和存储位置，确保文件以打开并有写入权限。然后，为了提高性能，数据会先写入文件缓存区，在根据缓存策略决定何时将文件混充去内容刷新到磁盘，写入文件完成后，操作系统会更新文件元数据，比如文件大小和修改时间等

**%%%%%cat xxx.txt 的运行过程**

shell会解析命令并调用操作系统的exec系统调用来启动cat程序。操作系统将cat的可执行文件加载到内存，接着，cat程序通过open系统调用打开.txt文件，并获得文件的文件描述符。程序通过调用read系统调用读取文件内容，操作系统将文件从磁盘加载到内核缓存区，cat程序逐行读取文件内容并打印到终端。读取完后，cat关闭文件并推出，shell返回命令提示符，整个流程完成。

**%%%%%怎么在磁盘上找到一个文件**

要想在磁盘上找到一个文件，主要依赖文件系统的目录结构和索引机制。首先操作系统会先根据路径从根路径向下查找目录项，目录向里面包含了文件名和inode编号，inode记录了文件的元信息，包含文件大小，权限，存储在磁盘上的数据块的地址，通过 inode 里的数据块指针，就能定位到磁盘上的物理存储位置，从而读取或写入文件内容。

**%%%%%将文件A插入文件B操作**

这个本质上，是将文件a的内容读出来，并在文件b的某个地方写入。先通过系统调用open打开ab文件，内核会找到文件b的inode信息。操作系统先把文件a的数据读入到内存缓冲区，然后在文件b中指定写入偏移，把数据从内存写入到文件b的缓存区，写入过程中如果需要扩展或移动数据块，文件系统会负责重新分配，并更新 B 的 inode 中的数据块指针和文件大小，最后把缓存刷新到磁盘，完成插入操作

**%%%%%文件页缓存(page  cache)如何写回磁盘**

又同步和异步两种策略，同步写时，系统调用会阻塞直到数据写入到磁盘；异步写时，数据先在缓存中保留，之后又内核后台线程扫描脏页并写回磁盘，并更新inode元数据

扩展:脏页值的是已经被修改但同步到磁盘的内存页

**%%%%%open文件时发生了什么？**

程序调用open打开文件时，用户态会发起系统调用进入内核，内核首先会根据路径名从根目录找到目录项，从而找到对应的inode,并检查当前进程是否有相应的访问权限。接着，内核会为这个文件创建一个file结构体，保存文件的打开状态（如读写偏移、模式），并让结构体内部成员指针指向该 inode，，并把这个File结构体放在内核全局文件表中，内核在当前进程的文件描述符表中分配一个最小可用整数，执行file结构体，并把这个整数返回给用户态，之后应用程序就可以通过文件描述符来对文件进行读写操作

内存缓冲区-page cache

**%%%%%你了解虚拟内存吗？**

虚拟内存是操作系统体构的一种内存管理机制，他是在进程看到的地址和真实的物理地址间加了一个抽象，每个进程都认为自己有一块连续的大内存，实际上进程里看到的这些虚拟地址会通过页表映射到物理内存或者磁盘上

那么肯定会准问，那这样有什么好处，为什么要这样设置？

实现了进程之间内存隔离；解决了物理内存不足的问题，因为它可以通过页表把部分虚拟内存映射到磁盘；提高了内存利用率，不同的虚拟内存可以映射到相同的物理内存中的只读数据

**%%%%%要是没有虚拟内存会怎样？**

要是没有虚拟内存，进程只能直接用物理内存，会带来几个问题，首先，进程间无法实现隔离，一个进程的数据可能被另一个进程篡改；内存利用率低，物理内存必须按块分配，容易产生严重的碎片问题；安全性也比较差，一个程序的错误可能直接导致整个系统崩溃。

**%%%%%怎样避免物理内存碎片化？**

内存碎片化可以通过引入虚拟内存和分页机制来避免，把进程看到的虚拟地址空间分成固定大小页，映射到物理内存的页框，这样就避免了分配连续大块内存，解决了外部碎片，对于内部碎片化，操作系统可以结合伙伴系统和slab分配器解决

扩展：

外部碎片：是总空闲内存足够大，但是分布不连续，无法满足大块申请；比如说现在我申请了100kb,150kb,100kb,然后释放了两个100kb,现在我要申请200kb，但是因为不连续，因此还得重新申请

内部碎片：是分配器在返回内存时，分配给程序的块比实际请求的要大；比如现在有个分配器内部有最小分配力度64kb,现在你申请了100kb,那么分配器会给你分配两个64kb的块=128kb,那么就会有28kb的内部碎片产生

怎样避免内部碎片：

**%%%%%那你了解伙伴系统马？**

伙伴系统是一种高效的内存分配和回收算法，他主要为了解决内存碎片化问题。他将内存划分为2的米次方大小的块，每个块都有一个伙伴。当分配内存时，系统根据请求大小向上取整到最近的2的米次方，要是当前没有空闲块，就会再上一级将他进行拆分，拆分出来的子块互为伙伴。在释放内存时，要是释放块的伙伴，那么可以进行向上一致合并，从而减少了内存碎片化

**%%%%%了解malloc的底层实现吗**？

当申请小内存时，malloc使用sbrk分配内存，他主要是将堆顶的sbrk指针向上移动来扩展堆的大小；当申请大内存时，使用的时mmap函数，这里无论时sbrk还是mmap他们申请的都是虚拟内存，为了提高性能，在访问申请的虚拟内存时再会根据缺页中断在内核中调用伙伴系统给他分配相对应的物理页，并建立虚拟内存和物理内存的映射。由于sbrk和mmap都是系统调用，那么每次申请内存，都要产生系统调用开销，这样会带来了两个坏处，第一就是上下文切换十分影响性能，其次就是这样申请容易产生碎片【因为堆是从低地址像高地址，要是低地址的内存没有释放那么高地址的内存也释放不了】那么为了解决这个问题，malloc采用了内存池的实现方法，首先申请一块大内存，然后将内存分为大小不同的内存块，malloc将大小差不多相同的内存块通过双向链表连接起来形成一个bin,malloc一共管理128个bin，像fast bin,small bin,large bin等等,每个bin都有自己适用的条件【像fast bin,就是程序运行连续申请小块内存，这样可能小的内存空间用完会在大的内存空间切出一块，这很费时间，那么fast bin就很好的解决了这个问题，在不大于max_fast的内存块被释放时，他不会被立即释放，他会将这个内存块存到fast bin里面。对于对于分配大内存，这里还有个特殊的sorted bin,他主要是在要是在fast bin只没有找到合适的内存块，那么会将fast bin内存块进行合加入到sorted bin中，就会在sorted bin中找，要是他也不能满足分配，那么会将sorted bin里面的内存块加入到后面的 large bin里面，那么现在往后遍历数组的bin还是没有分配到内存，那么首先他会在top chunk中为他分配内存，这里的top chunk是从mmap区域分配的一块大的空闲内存，要是这个也不满足，那么会直接从mmap来直接使用内存映射。】上面采用内存池的方法起始就是arena内部维护的，但是在面对多线程操作malloc，为了避免数据竞争，会添加互斥锁，但是发现这种情况每次只能处理一个线程效率太低了，那么就为每个线程分别创建一个arena,创建新的arena时候，arena会向此操作系统生成一块大的虚拟内存，这样就避免了同时去抢同一片空间的问题，但是这里又有一个问题，内存会被划分为free,used和available，free是不占用物理内存的，used和available都是占用物理内存的，但是used是应用使用的内存，但是available是没有被应用程序使用但是还占有物理内存的，这里需要均衡arena的数量，要是太少，会产生竞争问题，要是太多，有会产生内存碎片化问题，因为要是线程a的arena里面的available他有一块内存，比如说20kb,现在线程b需要申请20kb，但是由于线程a和线程b有不同的arena,所以用不了线程a的available,这就需要均衡处理。

**%%%%%了解tcmalloc吗?**

是google开发的一种高性能内存分配器，【thread-caching-malloc】，主要是解决了多线程环境下malloc的锁的竞争的问题

但是对于tcmalloc,他主要分为三个组件，front-end和middle-end和back-end,每个线程都有属于自己的front-end,共用middle-end,对于back-end,他会通过系统调用比如说mmap/brk申请大量内存，然后再切分给上层malloc。首先要是线程a有20kb的内存,那么他会将他放入middle-end中，要是线程b要申请20kb内存，会现在本地找，要是本地没有，他会先在middle中找，ok，找到了直接用就行了，可以解决malloc的问题频繁系统调用的问题

ai:用于理解

tcmalloc 的架构可以分为三层：

1. **Front-end（线程本地缓存层）**：每个线程都有自己的 ThreadCache，用于缓存小块内存。分配和释放小内存块时可以直接在本地完成，无需加锁，效率非常高。
2. **Middle-end（中央缓存层）**：所有线程共享一个 CentralFreeList。当线程的本地缓存用完或过多时，会批量地向中央缓存请求或归还对象，从而显著减少锁竞争。
3. **Back-end（页堆层）**：通过系统调用（如 mmap 或 brk）向操作系统申请大块的物理内存页（PageHeap），然后切分成更小的块提供给中央缓存使用。

举个例子：

- 线程 A 释放了 20KB 内存，如果本地缓存太多，它会把这部分内存批量归还给中央缓存（Middle-end）。
- 当线程 B 需要 20KB 内存时，会先从自己的 ThreadCache 找，没有再去 CentralFreeList 中取；
- 如果中央缓存也没有，则从 PageHeap（Back-end）申请新的页。

**%%%%%进程，线程，携程的区别？**

进程是资源分配的最小单位，线程是cpu调度的最小单位。进程拥有独立的内存空间，进程间资源相互隔离，进程里的进程贡献内存，但也拥有独立的寄存器，栈，上下文切换开销比进程小；携程他是用户态轻量级线程，依附于线程，是一对多的关系，切换开销极低，适合高并发

**那你知道携程有哪几种吗？**

携程分为有携程和无栈携程，goroutinue是有栈携程，拥有自己的上下文和执行栈，支持动态伸缩栈，无栈携程是一个线程共享携程栈，内存占用低，切换成本低，效率高，但是需要编译器状态机支持

**%%%%%进程间通信方式你知道哪些？**

首先每个进程他们从虚拟地址对应的物理地址中，用户地址空间是独立的，但是他们共用内核物理内存，因此要实现进程间通信，那么可定时要通过内核的，那么就有一下几种方式：

**管道，消息对列，共享内存，信号量和信号，socket**

**管道：**首先管道的类型分为匿名管道和命名管道，他们就是内核里的一串缓存，缓存的数据是无格式的流大小受限。那么想实现进程间通信，简单的是通过fork来实现父子进程间的通信，现在父进程通过pipe函数创建匿名管道，创将两个读写管道，然后fork一个子进程，因为创建的子进程会复制父进程的文件描述符，那么现在两个进程都有两个读写管道，为了避免混乱，一般就留下一个读的或者写的实现跨进程沟通。然后想要实现没有什么关系的进程间通信，他主要是创建命名管道，这个命名管道就是两个进程间进行交互的桥梁

**消息队列：**因为管道通信方式比较低效，不适合进程间频繁进行交换数据，那么就引入了消息队列。消息队列是保存在内核中的链表，他将要传递的消息体放在链表中即返回，然后接收者再从链表中读取，但是他对于消息体的大小有限制然后就是有数据在用户态和内核态之间的拷贝开销

**共享内存**：共享内存可以完美的解决用户态和内核态之间消息拷贝的开销问题，因为他等于是让生产者和消费者共享一块内存来实现消息的传递的，每个进程的虚拟空间对应的用户态物理内存是不一样的，那么就让他对应一样的物理内存就实现了内存共享(那我感觉这个跟上面说的内核没什么关系啊：共享内存虽然需要内核来建立映射，但真正读写数据是在用户态直接完成的，所以避免了频繁的内核态拷贝)

**信号量：**因为在共享内存的时候，要是有多个进程共享内存，那就可能会产生竞争，为了保证在任意时刻共享内存里的资源只能被一个进程访问，就出现了信号量。信号量起始是一个整形的寄存器，主要用于实现进程间的同步和互斥。对于互斥来说，需要将信号量初始化为1,当有一个进程访问资源时，就将这个信号量进行p操作也就是-1,这时候信号量变成0了，要是还有进程想要访问，发现再减就<0,就等待，此时要是上一个进程访问完释放了资源就是时的信号量+1然后唤醒阻塞的进程。同步是为了进程间能按照一定的顺序合作完成，那么需要将信号量初始化成0，这样假设现在有两个线程a,b,a负责生产消息，b负责读取消息，要是现在b先执行了，在p时信号量会变成-1,表示a现在还灭有生产数据，此时a阻塞，知道a生产了数据，信号量变成了0,就会唤醒b

**信号：**信号时为了通知进程有异常事件发生

**socket:**上面讲的都是在一台主机上的进程通信，要是想要实现不同之间的主机进行通信，那么就需要网络，就要用到socket，但是socket不仅可以跨即，也可以在本地，但是他不像tcp和udp那样，需要绑定ip地址和端居欧，而是绑定一个本地文件就可以了

**线程同步方式？**

互斥锁；自旋锁；读写锁；条件变量；屏障；信号量

互斥锁：在访问共享资源是对互斥量进行加锁，保证在访问共享变量的时候保持唯一性，他在等待获取锁的时候会进行足色，不占用cpu资源

自旋锁：自旋锁也是差不多，但是他在获取被占用的锁时他不会处于阻塞状态，而是仍然占用cpu资源，适合锁持有时间很短的场景，因为它不会让线程阻塞，而是循环等待

读写锁：对于对共享资源的访问，以读的模式则可以共享也就是多个线程进行访问；写的米时则需要以读占的形式，适合与读的操作远大于写

条件变量：配合互斥锁使用，等待某个条件成立再继续，比如生产者-消费者。

屏障：屏障就是让所有线程到达一个点后统一进行执行操作

信号量：信号量本质上是一个计数器，表示可同时访问的资源数量。线程获取资源时信号量减 1，如果信号量为 0，则阻塞等待；释放资源时信号量加 1，唤醒阻塞线程。

扩展：**详细讲一下自旋锁**

**你知道cas码，他会存在什么问题**
cas时一种乐观锁机制，通过指令compare-and-swap来实现无锁的原子操作
aba问题：就是一个变量他的值要是由a变化成了b然后又便会了a，此时cas还以为他没有发生任何变化，那么他就错过了中间b,解决方法引入版本号，或者给每个值带上时间辍
自旋开销大：主要是竞争激烈的情况下，因为cas是忙等状态，竞争激烈不断重时会浪费大量Cpu,因此他比较适合低竞争，但是要是高竞争，可以配合退避策略
cas一次只能操作一个内存位置，他无法保证的多个共享变量同时原子更新，解决方式，简单就是加锁被，要么还可以把这些共享变量放在一个结构体里面，进行整体封装


**cpu缓存一致性做的怎样实现**

首先多核cpu操作，要是一个cpu写会先在本地缓存写【本地缓存也就是cpu的l1/l2 cache里】，如果多个 CPU 同时读写同一内存地址，就可能出现缓存不一致。为了解决这个问题，处理器实现了 MESI 协议：

每个缓存行有4个状态

M【modified】已修改：数据只在cpu本地缓存里，和内存不一致

E【exclusive】独占：数据在本地缓存，和内存一致，但是其他cpu没有这个缓存

S【shared】共享：数据在所有cpu本地缓存里，和内存一样，大家都能读

I【invalid】无效：缓存里的数据无效，需要从内存或者其他cpu拉取

一致性的实现方式：假设个cpu0改了本地缓存，那么此时处于已修改状态，会通过总线广播消息，现在就是总线嗅探，每个cpu监听总线上的读写操作，那么此时其他cpu就接收到了这个失效消息，他们本地缓存的这个缓存行会进入无效状态【为了避免广播，可以通过中心化的目录记录那个cpu拥有缓存】
那么要是此时cpu1要读取这个缓存行发现这个缓存行时无效的，那么他会发出read请求，总线嗅探发现cpu0有这个缓存行并处以修改状态，那么会讲个请求发送给cpu0，cpu0响应请求，把这个缓存行直接通过总线传递给cpu1,同时cpu0讲自己这个缓存行的状态由已修改状态变为共享状态，cpu1缓存到了本地，那么他这个缓存行的状态由无效变为共享，要是现在再来一个cpu2要访问本地这个缓存行发现是无效，通言该法器read请求，总线发现cpu0和cpu1里面的这个缓存行都是共享，就随便找一个将他cpu里面的缓存行数据发送给cpu2并将cpu2本地缓存的缓存行的状态又改成共享状态，但是此时其实内存中数据还是旧的
那么他会问，那现在内存中的时旧的，需要保持内存和缓存中数据一致码
你了解内存屏障码
cpu为了提升性能，会做指令重排序和缓存优化，这个在单线程没有问题，但是在多线程可能会破坏语义，这样可能会改变指令执行的顺序，有的代码要是顺序变了，那么结果也会不一样，比如说线程1先设置x=0,然后flag=true,线程2判断flag=true,那么打印x,但是cpu可能会对指令进行重新排序，让线程1的顺序颠倒的话，此时打印出来x的值就不是1了，那么就可以通过内存屏障来解决这个问题
内存屏障分类：
读屏障；写屏障；全屏障；
**%%%%%死锁是怎样形成的**？

他需要满足四个条件才可以，互斥条件，持有并等待条件，不可剥夺条件，环路等待条件。

首先对于互斥条件就是一个共享资源在任何时可只能被一个进程持有；持有并等待条件是指一个进程持有1个资源但是他还像在持有另一个资源，但是另一个资源已经被另一个进城持有了，那么现在他就时等待状态。不可剥夺条件是指，一个资源只有被持有的进程时用完并释放之后才能被其他进程拥有（我怎么感觉这个和互斥说的这么像呢，还是不一样的，这个主要强调的时不能强行夺取);环路等待条件，就是a池有了资源1等待资源2,b持有资源2等待资源1这样就形成了环路等待

**%%%%%怎样排查死锁**？

可以通过pstack(它可以显示每个线程的栈跟踪信息)和gdb来进行排查。

通过pstack 进称号，多次进行调是，发现结果都一样，可以看到两个线程一直阻塞在获取锁的状态，当时就可以知道那可能是出现死锁状态了，然后用gdb来进行调式，我通过info thread来打印线程信息，切换到阻塞的线程，通过调用栈发现他在等a的锁，然后查看a的锁在哪，发现在另一个线程持有，而另一个线程又在等待这个线程已经持有的线程a

**%%%%%怎样解决死锁**

要打破索引，只需要破坏那四个条件中的一个就行了，可以使用资源有序分配法来破坏环路等待的条件，就是a线程和b线程要获取a,b锁，那么他们获取锁的顺序必须要保持一致，这样就可以了

**%%%%%讲一下大端和小端？**

地址就跟我们好图一样，喜欢从左到右是从小到达，那么地址也一样，从做到有就是低地址到高地址。

大端是将字节从高位到低位就像我们平时写数字一样；小端则是将字节从低位到高位。网络协议统一使用大端，x86架构是基于小端的

**%%%%%docker的底层原理：**

docker本质上不是虚拟机，它主要是利用linux内核提供的隔离和资源控制能力时显得轻量级容器话技术。它主要包括：namespace:进程隔离，docker里的每个容器就是一个进程，运行在namespace里面，他里面将进称号，网络什么的都进行了隔离；cgroups:资源限制：用来限制容器能使用的资源，防止了某个容器无限制的占用宿主机资源，保证多容器的公平性；overlayfs:分层文件系统：分成镜像层和容器层，镜像层是共享只读，容器是是分离可写

**%%%%%抢占式调度和非抢占式调度的区别：**

抢占式调度允许正在运行的进程被中断，从而把cpu分配给更高优先级的任务；

非抢占式调度时进程需要触动染出cpu才会被切换

**%%%%%冯诺伊曼体系结构：**

很久以前数据和程序存储地方是不一样的，数据存储在存储器，程序则存储在控制器，他提出了，将程序编码为数据和数据一起存放在存储器，实现了硬件和软件的分离
核心思想：
程序，数据以二进制都是先存在主存储器中，确定了计算机的五个组成部分：运算器，控制器，存储器，输入设备，输出设备
运算器的主要部件是算术逻辑单元alu,在控制信号的作用嗯下，完成算术运算了逻辑运算
控制器是计算机控制中心，他的流程：从内存取指令，翻译指令，分析指令，控制相关操作
存储器

**%%%%%时间轮？具体说下底层**

时间轮是一种高效管理大量任务的调度算法，通过环形数组来管理定时器。环形数组里面有slot数量【slot=槽位】，每个slot都是一个连链表，链表里面存放该时间点需要触发的任务；tick大小代表每次移动一个槽位经过的时间，每次tick移动，就会检查槽位，轮数=0 的执行，轮数>0 的减一。当前指针就是指向当前的槽位；假设现在有8个槽位，tick=2,当前指针=1,任务a是延迟21秒，那么他会放在哪里呢？

那就需要计算槽位和轮数：

槽位：（1+【21/2】向上取整）%8=4

轮数：21/2/8=1

优点：他只需要维护一个固定大小的数组，节省了内存；他插入是 O(1)，删除平均是 O(1)，最坏情况下可能退化成 O(k)，复杂度较低

缺点：不适合做长时间任务，只适合做短期，因为长任务他的时间轮可能很大，无法表示；然后就是他的灵活性不高，要是大多数任务都被分到同一个曹位，就会退化成链表；还有就是将任务容易，删除任务还需要扫描链表，比较麻烦

可以将他结合小根堆使用

小根堆：完全二叉树，每个结点小于等于子结点，也就是对的到小从上往下看是从小变大，他在插入时，会从堆低往上遍历，插入时O(logn),他删除是往下遍历，时间复杂度O(logn),获取最小值往下遍历，O(1),他嫩感召时间顺序处理所有任务，适合长时间任务

那么量者结合在一起，就可以解决长任务和短任务的问题

**%%%%%能讲一下select,poll和epoll的关系吗？**

select实现多路复用的方式是将以连接的socket都放到一个文件描述符集合，然后调用select函数将文件描述符集合拷贝到内核里，让内核来检查是否由网络事件发生，检查方式，通过遍历文件描述符的方式，当检测到有事件产生时，将次socket标记为可读或者可写，接着再把整个描述符集合拷贝回用户态里，然后又用户态还需要在遍历找到可读或者可写的socket,然后对他进行处理。而poll和select的区别就是解决了select1024限制问题，性能上没有什么优化。那么epoll是怎样做的，epoll在内核中使用红黑数来跟踪所有待检测的文件描述符，红黑数是个高效的数据结构，曾删改一般事件复杂度为logn;epoll具体实现原理，epoll使用事件驱动机制，内核维护了一个链表来记录就绪事件，当某个socket有事件发生时，通过回调函数内核将这个socket加入到就绪事件中，当用户调用epoll_wait函数时，会返回就绪事件列表中的个数，不需要像select/poll那样轮询扫描整个socket集合，达到提高了检测效率

举例：怎样触发read_event?

Epoll是单线程还是多线程

**%%%%%mmap:**

是一种内存映射机制，可以把文件或设备映射到进程的虚拟地址空间，让进程向读写内存一样访问文件内容，从而减少用户态和内核态之间的数据拷贝，提高i/o效率。调用mmap时，内核只在虚拟地址空间建立映射关系，并不分配物理内存，当进程首次访问这段虚拟地址时，会触发却缺页中断，内核会把文件里的数据从磁盘读到内核缓冲区[page cache],他主要用于文件映射和匿名映射，对于文件映射，他主要分为两类，map_shared,多进程共享，某个进程修改会变成脏页，之同步会文件；map_privated,单进程写时复制，即使修改了也不会同步到文件，修改对当前进程可见。对于匿名映射,不依赖文件，对于共享匿名映射主要用于父进程fork子继承两个进程共享内存通信，对于私有匿名映射，通常是malloc,然后他们本身不会写入磁盘文件，但如果内存不足，内核可能会把匿名页换出到 **swap 分区**，但是记住，匿名私有映射的数据即使落到磁盘，也只属于当前进程，不会被其他进程共享或泄露。

**就是文件映射他虚拟内存对应的物理内存他的数据可能需要和磁盘进行同步，但是匿名映射不需要**

**%%%%%说说写时复制？**

在fork一个子进程的时候，会将父目录与页表页一并复制，并将对应得物理页改为只读属性，此时父子进程间虚拟内存队赢得物理内存是一样的，二者可以对物理页进行读操作，但是在进行写操作的时候，硬件会检查物理页是否可写，发现是只读，因此会引发缺页中断，在缺页中断中，会为这块被写的虚拟地址重新分配物理页，将原有的物理页的内容复制过去，并将新写入的内容写入其中，这样做的好处是节省了内存

ai:写时复制（COW）是操作系统在 `fork` 时的一种内存优化策略。`fork` 后父子进程会共享同一份物理内存，但页表被复制，并且所有共享页会标记为只读。这样父子进程都能读相同的数据。当某个进程尝试写入时，会触发缺页异常，内核分配一个新的物理页，把原来的内容复制过去，再更新页表，使该进程能在新页上写入。这样既保证了进程间的隔离，又能避免在 `fork` 时做大量没必要的内存复制，从而节省内存、提高效率。

**%%%%%什么是中断**

中断是系统用来响应硬件请求的一种机制，操作系统在收到硬件中断请求时，会打断正在执行的程序，调用内核中断来响应请求

通俗来讲，就像你在公司完成一项任务，这是紧急开了一个会，这个会就像中断，我们快速去开完，更有利于我们完成下面的工作

**%%%%%硬中断vs软中断**

情况：要是中断处理时间过长，其他设备发来中断请求可能会丢失

就像你还是被拉去开会，在开会过程中，又有了一场会议需要你参加，但是你参加不了了

解决方法：将中断过程分为上半部分【硬中断】和下半部分【软中断】

上半部分用来快速处理中断，下半部分用来延迟上半部分未完成的工作

就那上面的举例，我依然被拉去开会，在会上我让将重点，后面的之后让同事讲给我，那么我就可以继续参加第二场会议了

应中断是处理硬件请求，回答端cpu正在执行的任务，需要快速执行

软中断是内核触发，耗时较长

**%%%%%用户态和内核态：**

用户态和内核态划分位这两类主要原因是为了保护资源和隔离权限划分的；首先他们特权及不同，内核态是0最高级，用户态是3最低级；因为内核态权利比较大，他直接可以访问硬件资源，但是对于用户态，他主要是简单的应用程序，这种崩溃了也不会对整个系统有影响；要是想从用户态切换到内核态，可以通过系统调用来实现

**%%%%%僵尸进程和孤儿进程：**

孤儿进程简单理解就是没人管了，也就是父进程先退出，子进程此时还在运行，此时子进程会被init进程收养

僵尸进程就是子进程先退出，但是父进程没调用wait()去回收他的资源，此时就会占用资源；处理方法就是查掉他的父进程，让他成为孤儿，交给init进行回收

怎样查看僵尸进程：我一般是通过htop去查看，看他的状态列要是z就代表他是个僵尸进程要及时处理

为什么僵尸进程很不好：因为他不仅占用资源还占用进程好还不能被杀死，因为他已经死了，只是父进程不负责任，没给他收尸，要是僵尸进程积累太多，会时的进程号被占满，那么就无法在创建新进程了

**说一下write的整个流程：**

在用户态调用write函数时，会将write的系统调用号存入eax,将后面的fd,buf,size分别存入ebx,ecx,edx寄存器，然后他会执行int 0x80软中断，此时陷入内核，cpu会在中断描述符表中找相应的系统调用号，找到对应的内核函数，保存上下文，执行内核函数，然后内核从进程结构取出fd对应的file结构体，然后虚拟文件系统从结构体里面找到的具体的类型

要是时普通文件，内核会将用户缓冲区的数据复制到page cache中,然后将这个page cache标记为脏页，然后由后台的writeback线程异步进行刷盘

要是是socket,那么他会将用户态数据拷贝到内核缓冲区，通过网络协议栈发送到网卡，最终网卡将数据发送到远端的网卡

你了解dma拷贝吗

我理解的是dma可以解放Cpu,总的来说是这样的，在没有dma之前，假设用户态调用了read函数，那么首先陷入内核，然后cpu发起i/o请求，那么磁盘会将数据放入到磁盘控制器缓冲器里面，然后写完之后发起中断信号给cpu,cpu接受到中断之后就将磁盘控制器缓冲区里面的数据放入到page cache里面，然后cpu再将page cache里面的数据放入用户的缓冲区里面，而dma代替了从磁盘控制器缓冲区到page cache的操作，这时候cpu就可以去处理别的事情

**零拷贝：**

说起零拷贝，就需要先说一下他产生的原因：在没有零拷贝的时候，调用一次read和write这个流程，首先用户态调用reda,那么会由用户态到内核态这是一次上下问切换，然后首先dma将磁盘的数据拷贝到page cache,cpu将page cache的数据拷贝到用户态，这次又由内核态切换到了用户态，这是第二次上下文切换，然后在用户态调write函数，由用户态切换到内核态，这是第三次上下文切换，然后cpu将用户态数据拷贝到socket缓冲区里面，然后由dma再将数据由socket缓冲区拷贝到网卡，然后在切换会用户态，这样算下来一共进行了四次上下文切换，cpu进行的数据拷贝有两次，dma进行的数据拷贝有两次

那么0拷贝就主要是为了解决频繁上下文以及拷贝产生的性能问题

一共有两种方式

第一种方式是mmap+write，也就是将read变成mmap,用了mmap后，cpu就不用将数据从page cache传给用户态，而是通过映射的方式让内核和用户共享这一片内存，在write的时候，cpu直接从page cache里面拷贝数据到socket缓冲区就行，这种方式不上面那个减少了一次cpu进行的数据拷贝

第二种方式就是sendfile,他这个函数的参数里面直接包含了目标端和源端的文件描述符，那么直接可以代替read和write两个系统调用，那么就等于减少了两次上下文切换，也减少了一次cpu进行的数据拷贝

这里确实很优化了，但是只是对于小文件来说，因为page cache只能对于小文件来说产生优化，因为cpu直接访问磁盘太影响性能了，那么会通过dma先将磁盘的数据放到page cache内存里面，要是cpu来访问数据就先访问page cache的数据，page cache里面一般存放的是最近被访问的数据，然后他还有一个预读功能，会把访问的数据后面也加入到page cache,也进一步提高了性能哪个，但是这个的前提是数据小，因为page cache说来也是内存，根本就没有多大的空间，那么对于大文件就不起作用了

对于大文件的数据传输要用异步i/o和直接i/0，异步i/o的意思是正常的read操作，当用户态调用read后不等待数据传过来就先进行返回，等cpu将数据从page cache读到用户态值后通知用户；直接i/o指得是绕过page cache的i/o,并且内核会进肯哪个多的将多个I/o请求合并成一个更大的i/o请求发给磁盘来减少磁盘操作

为什么用户数据能拷贝到内核的原理是什么？****

就是在用户态调用read/write函数的时候，传递的buffer指针是用户空间的地址，内核会先检查这个指针是否合法，要是合法，内核会通过页表将这个地址映射到实际的物理页，然后执行拷贝，对于拷贝，内核不能直接用memecpy来拷贝用户数据，那样可能会触发却也中断，非法访问，linux专门提供了专门的函数，copy_from_user()和copy_to_user(),保证了安全访问

至于为什么内核不能用memecpy来进行拷贝的原因是他无法预防缺页中断，**内核态的缺页中断比用户态严重多了**

为什么呢

用户态访问一个不存在的虚拟地址时，cpu会触发缺页中断，此时内核可以进行处理，先看他要申请的是否是合法的地址【怎样判定这个虚拟地址是否合法】，要是是合法的，呐和就会为他分配相应的物理地址并进行虚拟地址和物理地址之间的映射。要是非法的虚拟地址，内核会给进程发送一个sigsegv信号，进程崩溃退出【为什么发送一个信号他就可以崩溃退出】，但是系统的其他进程都可以正常工作

但是要是内核态发生了缺页中断，在访问合法虚拟地址的时候，那么现在有链中情况，对于内存中有空闲物理页还好说，直接建立映射就好了，一般很快；但是对于内存种没有空闲的物理页的情况，那么就会触发磁盘i/o这是很慢的操作，在用户态比较好处理，直接让Cpu执行其他进程就可以了，但是对于内核遇到这种情况，此时让内核去等待磁盘i/o时不现实的，因为要时遇到一些中断处理时不允许睡眠的，要是正在执行中断处理时遇到了这种情况，将对于内核来说是一个灾难，或者内核持有自旋锁的情况也不允许有睡眠，因为这些都属于元子操作，不允许被打断，在对于访问的是非法的虚拟地址时，内核只能选择oops导致整个系统宕机

**怎样判断一个虚拟地址是否合法？**

就是看这个虚拟地址空间是否在进程的虚拟地址空间这个结构体【mm_struct】对应的虚拟内存区域【VMA】，要是在里面，而且访问权限匹配，就可以被认为是一个合法缺页

**为什么内核给进程发送sigsegv信号进程就会崩溃**

内核发送信号给进程实际上就是把这个信号放到进程的pending队列里面，调度到该进程时，内核的信号处理机制发现有位处理的信号，他会按照注册的hander或者默认行为执行，当然这个信号就走的默认路线，也就时杀死该进程

你按下ctrl+c计算机之后的流程是怎样
当我按下ctrl+c,键盘会将这个组合转换成扫描码，通过键盘控制器传递给cpu,cpu收到了来自键盘的中断请求，会从用户态切换到内核态执行相应的键盘中断函数，这个函数他会把扫描码交给linux内核的输入子系统，最终进入终端驱动，在终端驱动里解析出来ctrl+c并将他翻译成一个sigint信号，并投递给前台进程组,然后内核会那这个信号记录到进程的pending队列，然后在内核态返回到用户态时，内核会在进程的pending队列检查这个进程是否有没处理的信号，范县有而且这个信号每有对应的handler函数，那么就会执行默认动作，也就是杀死这个进程
那为什么在图像界面按ctrl+c不会杀死进程：因为输入子系统将扫描码变成了键值对后不是交给终端驱动，而是交给图形界面，但是在这里，这个不会触发信号的产生

ai:在图形界面下按 Ctrl+C 不会杀死进程，是因为键盘事件虽然同样先经过输入子系统从扫描码转换成键值事件，但这些事件不是交给 TTY 驱动，而是交给了图形界面的输入系统（比如 Xorg/Wayland 及应用程序）。只有经过 TTY 驱动时，Ctrl+C 才会被解释为中断字符（VINTR），内核才会把它翻译成 SIGINT 信号并投递给前台进程组；而在图形界面里，它只是一个普通快捷键（比如“复制”），不会触发内核信号。

**现在的服务器或者pc都是多核了，cpu如何发挥出多核的功能**

**解释一下什么是脏读**

我认为脏读就是一个事务或者线程，读到了另一个事务或者线程还没有提交或者写完的数据。在数据库中，事务a修改了一行数据但是还没有提交，此时事务b读取了这个数据，但是a之后有进行了回滚，那么b读到的数据就是脏读；在造作系统多线程中，也有类似的情况，线程a正在写变量，另一个线程b在写入完成前就读取了那个变量，可能得到不完整的数据。

解决方法：

数据库：可以采用读已提交来避免

操作系统多线程：操作时加锁来保证对数据的原子操作

读屏障的写屏障【内存屏障】

**IO操作需要CPU么，什么时候需要，磁盘IO和网络IO的区别**

是，但是是少量。不想写。。。

**进程调度算法有哪些？**

我知道的主要是包含先来先服务，也就是按照进程到达的先后顺序来进行调度，这样要是前面进程占用的cpu时间过长，后面占用cpu端的进程却执行不上

短作业优先：也就是会优先执行时间最短的进程，那这样可能导致长作业一致得不到执行一直处饥饿状态

时间片轮转：给每个进程分配固定的时间片，时间便到了就进行切换

优先级调度：每个进程都会有优先级，优先级高的先执行，但是这个也要防止低优先级的一直得不到调度处于饥饿状态

总结：实际操作系统中用的一般是多级反馈队列，结合了上面几种算法

多级反馈队列：他主要是这样的，他会将进程分到多个优先级不同的队列里面，不同队列里面时间片的大小也不一样，高优先级队列的时间片比较短，低优先级则相反，【那每个优先级相同的队列里面的时间片是否像等】，新来一个进程会先进入到最高优先级队列，要是在时间片内没有执行完，就会对这个进程进行降级操作，把他讲到下一级，这样的话，短作业会优先被执行，而长作业会被逐个降级，防止长期占用Cpu，而且长时间处于饥饿的进程会提升优先级队列

完全公平调度：它主要是通过红黑数和虚拟时间运行来实现的，尽量保证每个可运行的进程公平的Cpu时间

主要细节：虚拟运行时间主要就是一运行的时间*加权分数之后得到的，每个进程都是放在红黑数中的，然后每次要取的话就取红黑树中进行加权后最小【红黑数最左叶子节点最小】的进程出来运行，因为将优先级高的一般加权的数字是越小，所以他一般占用cpu时间会比较长

高优先级进程累加 vruntime 慢，所以它占用 CPU 时间更多，低优先级累加快，占用少，从而尽量保证公平

**缓存淘汰策略**

微服务优缺

**虚拟内存的作用**

使得地址空间进行了隔离：每个进程看到的地址空间都是独立的，互相不影响，这样不会出现一个进程的崩溃导致系统的崩溃

扩大了可用内存：虚拟内存的swap机制可以在内存不够用时讲不常用的数据从内存swap到磁盘

可以实现共享内存：多个进程可以通过映射到同一快物理内存来共享代码和数据，就像父子进程一样



常见内存管理方式有哪些？

**内存泄漏与内存溢出分别指什么？**

内存泄漏是申请单没有释放内存，导致可用内存月来越少，就像c语言malloc了但是没free一样；内存溢出是申请了超过系统限制的内存导致程序崩溃

**硬链接和软链接区别**

硬链接和软链接是两种不同的文件链接方式：**硬链接是多个文件名指向同一个数据块，软链接是一个文件名指向另一个文件名**

**什么是中断和异常？**

中断是外部设备触发的异步事件 异常是程序执行时出现的同步错误 中断和异常都先保存当前的状态 通过对应的中断向量表或者异常向量表查找处理程序 中断处理完返回执行 异常处理完继续执行或者终止

**4 GB 机器申请 8 GB 内存会怎样？**

1.可以分配8g虚拟内存

2.虚拟内存使用超过4g时会触发swap

3.超过swap上限触发oom，可能直接kill这个进程

**内存满了会发生什么**

当系统内存逐渐被占满时，Linux 会分阶段地进行内存回收。

首先，当内存使用超过一定阈值时，内核会唤醒后台线程 kswapd 异步回收不用的内存页，比如释放文件缓存或写回脏页到磁盘，这个过程不会影响程序执行。

如果后台回收速度跟不上分配需求，分配内存的进程就会触发直接回收，自己同步清理内存，这时程序会被阻塞。

若回收后仍然没有足够空间，系统就会触发 OOM Killer，挑选并杀掉一个占用内存最多、非关键的进程以释放内存。

回收的页分为文件页和匿名页两类：文件页干净的直接释放，脏页需写回磁盘；匿名页没有文件后备，只能通过 swap 换出到磁盘保存。整个机制保证系统在内存紧张时尽量维持运行，实在无法回收才会触发 OOM。

细节：他在oom后并不是简单的杀死占用内存最多的进程，而是通过oom score平分机制来选择【内存占用量，进程优先级等】，首先内核会扫描

脏页：就是修改的物理内存页但是还没有同步到磁盘

**操作系统读取磁盘有什么特点？**预读

深拷贝和浅拷贝的区别？

**%%%%%了解linux用了哪些命令**

